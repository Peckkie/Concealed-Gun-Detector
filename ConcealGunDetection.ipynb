{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ConcealGunDetection.ipynb","provenance":[],"collapsed_sections":["NxDa-CvSaSup","StGwWzr0_DeI"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"ieJ3fUl76CCb","colab_type":"text"},"source":["# Mount Drive\n"]},{"cell_type":"code","metadata":{"id":"aygrRsHZd4UC","colab_type":"code","outputId":"b683f025-467b-4e94-ca1c-bfcb7af5dfcf","executionInfo":{"status":"ok","timestamp":1584326358353,"user_tz":-420,"elapsed":43148,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhjI8suu_5SmV03uqGiIwG7KaIUmD0V7yzyzaJ7jQ=s64","userId":"14117620575648423760"}},"colab":{"base_uri":"https://localhost:8080/","height":175}},"source":["from os.path import join\n","from google.colab import drive\n"," \n","ROOT = \"/content/drive\"\n","drive.mount(ROOT)\n"," \n","PROJ = \"My Drive/DetectConcealGun\" # This is a custom path.\n","PROJECT_PATH = join(ROOT, PROJ)\n"," \n","\n","%cd ~/content\n","%cd drive/My Drive/DetectConcealGun/app"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n","[Errno 2] No such file or directory: '/root/content'\n","/content\n","/content/drive/My Drive/DetectConcealGun/app\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NxDa-CvSaSup","colab_type":"text"},"source":["# Detecting Concealed Gun"]},{"cell_type":"code","metadata":{"id":"BgV5EH4ebQXa","colab_type":"code","outputId":"6d5c72e3-17cc-42b5-a14c-d065eda58835","executionInfo":{"status":"ok","timestamp":1583213892376,"user_tz":-420,"elapsed":3869,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhjI8suu_5SmV03uqGiIwG7KaIUmD0V7yzyzaJ7jQ=s64","userId":"14117620575648423760"}},"colab":{"base_uri":"https://localhost:8080/","height":245}},"source":["!pip install flask-ngrok"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.21.0)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.1)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2019.11.28)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.1)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Eidnb-DPoDz3","colab":{}},"source":["from flask_ngrok import run_with_ngrok\n","from flask import Flask\n","from flask import render_template, request, redirect, flash, url_for\n","from werkzeug.utils import secure_filename\n","import os\n","import subprocess\n","import json\n","import pandas as pd\n","import numpy as np\n","import glob\n","import cv2\n","import pickle\n","from sklearn.preprocessing import StandardScaler\n","import shutil\n","import pathlib\n","from statistics import mean \n","\n","\n","app = Flask(__name__, static_folder=\"files\")\n","run_with_ngrok(app)   #starts ngrok when the app is run\n","\n","app.config[\"VIDEO_UPLOADS\"] = \"/content/drive/My Drive/DetectConcealGun/app/files\"\n","app.config[\"ALLOWED_VIDEO_EXTENSIONS\"] = [\"MP4\",\"MOV\",\"AVI\"]\n","\n","\n","def convert_tomp4(clipname):\n","  clipnames = clipname.split(\".\")\n","  avi_file_path = '/content/drive/My Drive/DetectConcealGun/app/files/result.avi'\n","  output_name = 'app/files/results/result_' + clipnames[0]\n","  print(output_name)\n","  os.popen(\"ffmpeg -i '{input}' -ac 2 -b:v 2000k -c:a aac -c:v libx264 -b:a 160k -vprofile high -bf 0 -strict experimental -f mp4 '{output}.mp4'\".format(input = avi_file_path, output = output_name))\n","  os.chdir(\"/content/drive/My Drive/DetectConcealGun/app\")\n","  print(\"It's success!\")\n","\n","def framestoVDO(clipname):\n","  os.chdir(\"/content/drive/My Drive/DetectConcealGun\")\n","  path = 'app/files/images/'\n","  img_array = []\n","  for filename3 in glob.glob(path+'*.jpg'):\n","    img = cv2.imread(filename3)\n","    height, width, layers = img.shape\n","    sizes = (width,height)\n","    img_array.append(img) \n","  \n","  out = cv2.VideoWriter('app/files/result.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, sizes)\n","  for i in range(len(img_array)):\n","    out.write(img_array[i])\n","  out.release()\n","  print(\"video created\")\n","  convert_tomp4(clipname)\n","\n","\n","\n","#NOTIFY LINE*****\n","\n","def notifyFile(filename):\n","    file = {'imageFile':open(filename,'rb')}\n","    payload = {'message': 'พบบุคคลที่มีความเสี่ยงในการอำพรางอาวุธปืนในพื้นที่ของคุณ!'}\n","    return _lineNotify(payload,file)\n","\n","def _lineNotify(payload,file=None):\n","    import requests\n","    url = 'https://notify-api.line.me/api/notify'\n","    token = '7JODPqwRqL73hrp1To1AYma0bI7evyKTcHtxXnjulWX'\t#EDIT\n","    headers = {'Authorization':'Bearer '+token}\n","    return requests.post(url, headers=headers , data = payload, files=file)   \n","\n","def Notify_Line(APIC):\n","  os.chdir(\"/content/drive/My Drive/DetectConcealGun\")\n","  aray1 = list()\n","  for f in glob.glob('app/images/*.jpg'):\n","      aa1 = (os.path.split(f)[-1])\n","      aray1.append(aa1)\n","  piclist = list()\n","  meanpic = list()\n","  for i in aray1 :\n","    person = APIC[APIC[0]==i]\n","    per = person[person['Class'] == 1]\n","    if len(per) > 0:\n","      bb = i\n","      piclist.append(bb)\n","    piclist_df = pd.DataFrame(piclist)\n","\n","  if len(piclist) != 0:\n","    for n in piclist : ##\n","      person = APIC[APIC[0]==n]\n","\n","      r =  [1.0,2.0,3.0,4.0,5.0]\n","      arealist = list()\n","      #Pose position person /\n","      for m in r :\n","        per = person[person[52] == m]\n","        if len(per) > 0:\n","          #select body point\n","          X_min = int(min(min(per[range(4,52,3)].values.tolist())))-50\n","          X_max = int(max(max(per[range(4,52,3)].values.tolist())))+100\n","          Y_min = int(min(min(per[range(2,52,3)].values.tolist())))-50\n","          Y_max = int(max(max(per[range(2,52,3)].values.tolist())))+100\n","          area = (Y_max-Y_min)*(X_max-X_min) #Box area \n","          arealist.append(int(area))\n","          meanlist = mean(arealist)\n","      meanpic.append(int(meanlist))\n","      meanpic_df = pd.DataFrame(meanpic)\n","    meanpic_df.reset_index(inplace=True) #set key\n","    piclist_df.reset_index(inplace=True)#set key\n","    meanpicdf = piclist_df.join(meanpic_df, on='index', how='left', rsuffix='mean')\n","    meanpicdf = meanpicdf.drop(columns=['index','indexmean'])\n","    Maxarea = meanpicdf.max()\n","  if len(piclist) != 0:\n","    print(notifyFile('app/files/images/'+Maxarea[0]))\n","\n","\n","def person_box(APIC,video_input):\n","  APIC3 = APIC\n","  aray = list()\n","  for f in glob.glob('image/*.jpg'):\n","      aa = (os.path.split(f)[-1])\n","      aray.append(aa)\n","\n","  if os.path.exists('app/files/images') :\n","    shutil.rmtree('app/files/images')\n","  os.mkdir('app/files/images')\n","  path = 'app/files/image/'\n","  for i in aray : ##\n","      images = cv2.imread(path+i,cv2.IMREAD_COLOR)\n","\n","      person = APIC[APIC[0]==i]\n","      r =  [1.0,2.0,3.0,4.0,5.0]\n","      #Pose position person /\n","      for m in r :\n","          per = person[person[52] == m]\n","          if len(per) > 0:\n","              #select body point\n","              X_min = int(min(min(per[range(4,52,3)].values.tolist())))-50\n","              X_max = int(max(max(per[range(4,52,3)].values.tolist())))+100\n","              Y_min = int(min(min(per[range(2,52,3)].values.tolist())))-50\n","              Y_max = int(max(max(per[range(2,52,3)].values.tolist())))+100\n","              clas = int(per['Class']) #\n","              if clas == 1:\n","                  color = (0,0,255) #RED\n","                  thickness = 20\n","                  images = cv2.rectangle(images, (X_max,Y_min), (X_min,Y_max), color, thickness)\n","                  scor = float(\"%.4f\"% per['Class_1'])*100\n","                  name = 'Gun'+': '+str(scor)+'%'\n","                  font = cv2.FONT_HERSHEY_SIMPLEX \n","                  fontScale = 2\n","                  # Line thickness of 2 px \n","                  thicknes = 7\n","                  images = cv2.putText(images, name, (X_max,Y_min-20), font, fontScale, color, thicknes, cv2.LINE_AA) \n","              else :\n","                  color = (0, 255, 0) #GREEN\n","                  thickness = 20\n","                  images = cv2.rectangle(images,(X_max,Y_min), (X_min,Y_max), color, thickness)\n","                  scor = float(\"%.4f\"% per['Class_0'])*100\n","                  name = 'None'+': '+str(scor)+'%'\n","                  font = cv2.FONT_HERSHEY_SIMPLEX\n","                  fontScale = 2\n","                  # Line thickness of 2 px \n","                  thicknes = 7\n","                  images = cv2.putText(images, name, (X_max,Y_min-20), font, fontScale, color, thicknes, cv2.LINE_AA)\n","              cv2.imwrite('app/files/images/'+i, images)\n","  Notify_Line(APIC)\n","  framestoVDO(video_input)\n","\n","\n","\n","\n","\n","\n","def data_join (file1, file2,video_input):\n","  #load Class\n","  Class = pd.read_csv(file1) #2041(Class), 2042(Scores)\n","  print('CLASS TABLE','==========>','\\n',Class)\n","  #load APIC\n","  APIC = pd.read_csv(file2,header=None) \n","  print('APIC TABLE','==========>','\\n',APIC)\n","  r =  [1.0,2.0,3.0,4.0,5.0]\n","  m = range(0,5)\n","  A = APIC[52]\n","  B = APIC[52]#*Sores0\n","  C = APIC[52]#*Sores1\n","  for n in m :\n","    di = Class[Class['Unnamed: 0']==n]\n","    if len(di) > 0:\n","      clas = int(di['0_Predict'])\n","      cl = int(di['Unnamed: 0'])\n","      score_0 = float(di['Class_0'])\n","      score_1 = float(di['Class_1'])\n","      if cl == 0:\n","        A = A.replace(1.0,clas)\n","        B = B.replace(1.0,score_0)\n","        C = C.replace(1.0,score_1)\n","      elif cl == 1:\n","        A = A.replace(2.0,clas)\n","        B = B.replace(2.0,score_0)\n","        C = C.replace(2.0,score_1)\n","      elif cl == 2:\n","        A = A.replace(3.0,clas)\n","        B = B.replace(3.0,score_0)\n","        C = C.replace(3.0,score_1)\n","      elif cl == 3:\n","        A = A.replace(4.0,clas)\n","        B = B.replace(4.0,score_0)\n","        C = C.replace(4.0,score_1)\n","      elif cl == 4:\n","        A = A.replace(5.0,clas)\n","        B = B.replace(5.0,score_0)\n","        C = C.replace(5.0,score_1)\n","\n","  APIC['Class'] = A\n","  APIC['Class_0'] = B\n","  APIC['Class_1'] = C\n","  #check person\n","  person = len(Class)\n","  APIC = APIC[APIC[52] <= person]\n","  person_box(APIC,video_input)\n","\n","def mode_RF(Data,video_input): \n","  #reset index\n","  Data.reset_index(drop=True, inplace=True) \n","  X_test = Data.values.tolist()#dataframe to list\n","  \n","  #Load model\n","  filename = \"app/model_RF.pkl\"\n","  with open(filename, 'rb') as file:\n","    model = pickle.load(file)\n","  \n","  #prediction\n","  y_pred= model.predict(X_test)\n","\n","  # show the inputs and predicted outputs\n","  P_data=list()\n","  for i in range(len(X_test)):\n","    P_out = y_pred[i]\n","    P_data.append(P_out) \n","  # Calling DataFrame constructor on list \n","  P_datadf = pd.DataFrame(P_data) \n","  # check class\n","  Data.reset_index(drop=True, inplace=True)#reset index\n","  Data.reset_index(inplace=True) #set key\n","  P_datadf.reset_index(inplace=True)#set key\n","  # keep the predictions for class \n","  df = Data.join(P_datadf, on='index', how='left', rsuffix='_Predict') #join left\n","  df = df.drop(columns=['index_Predict']) #drop don't select\n","\n","    \n","  #prop each class\n","  prob = model.predict_proba(X_test)\n","  prob_out_df = list()\n","  for i in range(len(X_test)):\n","    prob_out = prob[i]\n","    prob_out_df.append(prob_out) \n","  # Calling DataFrame constructor on list \n","  prob_df = pd.DataFrame(prob_out_df) \n","  prob_df.reset_index(drop=True, inplace=True)#reset index\n","  prob_df.reset_index(inplace=True) #set key\n","  prob_df = prob_df.rename(columns={0: \"Class_0\", 1: \"Class_1\"}) #ChangName\n","  df = df.join(prob_df, on='index', how='left', rsuffix='_')\n","  df = df.drop(columns=['index','index_'])\n","\n","  # threshold < 0.6 \n","  m = range(0,5)\n","  for n in m :\n","    di = df[df['index']==n]\n","    cla = di['Class_1'] \n","    for k in cla :\n","      if k < 0.6 :\n","        di['0_Predict'].replace({1: 0}, inplace=True)\n","    df[df['index']==n] = di\n","  df = df.drop(columns=['index'])\n","  print('Check Class for Prediction***', '\\n', df)\n","  # Save .CSV\n","  df.to_csv('result_model_prediction.csv')\n","  data_join('app/files/result_model_prediction.csv', 'app/files/save_apic.csv',video_input)\n","\n","def data_train(video_input):\n","  file= 'app/files/Fature_to_Test.csv'\n","  Data = pd.read_csv(file,header=None)\n","  mode_RF(Data,video_input)\n","\n","def prepare_idx(idkp,video_input):\n","  maxjpg =[]\n","  for key, value in idkp.items():\n","    maxjpg.append(max([int(s) for s in key.split('.') if s.isdigit()]))\n","  maxjpg = max(maxjpg)\n","  print('max.jpg = ',maxjpg,'.jpg')\n","\n","  name_column=['XNose','YNose','XLEye','YLEye','XREye','YREye','XLEar','YLEar','XREar','YREar','XLShoulder','YLShoulder','XRShoulder','YRShoulder','XLElbow','YLElbow','XRElbow','YRElbow','XLWrist','YLWrist','XEWrist','YEWrist','XLHip','YLHip','XRHip','YRHip','XLKnee','YLKnee','XRKnee','YRKnee','XLAnkle','YLAnkle','XRAnkle','YRAnkle']\n","  featvec = list()\n","  for idxn in range(1,6,1) :\n","    # create list name pic .jpg ให้วนลูป\n","    jpglist  = list()\n","    pic = ['%s.jpg']\n","    for f in range(1,maxjpg+1,1): \n","      link = pic[0] % (f)\n","      jpglist.append(link)\n","\n","    frame, keypoints, idx = [], [] , []\n","    for key, value in idkp.items():\n","      picx = idkp[(key)]\n","      for p in picx:\n","        frame.append(key)\n","        keypoints.append(p['keypoints'])\n","        idx.append(p['idx'])\n","        df = pd.DataFrame() # create empty dataframe \n","        df['frame'] = frame\n","        df['keypoints'] = keypoints\n","        df['idx'] = idx\n","        apic = df\n","    \n","    jpglistdf = pd.DataFrame(jpglist, columns=['frame']) # Create jpglist dataframe\n","    pointn = apic[apic['idx'] == (idxn)]\n","    allFrame = pd.merge(jpglistdf , pointn[['frame', 'keypoints']], on='frame', how='left')\n","    # Replace NaN with list [-1,-1,-1, .  .  . ,-1] (51 item totol)\n","    allFrame.loc[allFrame['keypoints'].isnull(),['keypoints']] = allFrame.loc[allFrame['keypoints'].isnull(),'keypoints'].apply(lambda keypoints: [-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1])\n","    # Keypoint\n","    kpall = allFrame['keypoints']\n","    # remove c \n","    keypointls = list()\n","    for frm in kpall:\n","      frm = [round(i,3) for i in frm]  # convert a list into list with 3 decimal places\n","      for i in frm:\n","        if i <= 1 and i >= 0 :\n","            frm.remove(i)\n","      keypointls.append(frm)\n","\n","    # convert list to array\n","    keypointar = np.asarray(keypointls)\n","\n","    #ปรับค่า X,Y Nose\n","    arrayper = keypointar\n","    X_Zero = arrayper[:,0] #X point Zero\n","    Y_Zero = arrayper[:,1] #Y point Zero\n","    l=list()\n","    for i in range(0, 34):\n","      if(i%2) == 0:\n","        A = abs(arrayper[:,i] - X_Zero)\n","      else:\n","        A = abs(arrayper[:,i] - Y_Zero)\n","      l.append(A)\n","\n","    #Z Score\n","    \n","    scaler = StandardScaler()\n","    scaler.fit(l)\n","    lstand = scaler.transform(l)\n","    datalistdf = pd.DataFrame(lstand, name_column)\n","    df = datalistdf.T\n","\n","    #กรณี มากกว่า 60 เฟรม จะเริ่มเก็บจากเฟรมสุดท้าย\n","    (naa,nbb) = lstand.shape\n","    D1 = list()\n","    for r in range(0,34):\n","      for t in range(nbb-60,nbb):\n","        dat1 = lstand[r,t]\n","        D1.append(dat1)\n","    datalistdf1 = pd.DataFrame(D1)\n","    df1 = datalistdf1.T\n","    df2 = df.values.tolist()\n","\n","    # featvec.append(df1)\n","    # กรณีที่จับได้น้อยกว่า 50%\n","    ccv0 = 0\n","    for cv1 in df2:\n","      for cv0 in cv1:\n","        if cv0 == 0:\n","          ccv0 = ccv0 + 1\n","    if ccv0 < 1700:  #old ccv0 < 1020\n","      featvec.append(df1)\n","\n","  featvec2 = pd.concat(featvec)\n","  np.savetxt('app/files/Fature_to_Test.csv', featvec2,delimiter=',' )\n","  np.savetxt('app/files/save_apic.csv',apic,fmt=['%s','%s', '%f'],delimiter=',')\n","  data_train(video_input)\n","\n","def read_json(video_input): #read json file\n","  os.chdir('/content/drive/My Drive/DetectConcealGun')\n","  with open('app/files/alphapose-results-forvis-tracked.json','r') as myfile:\n","    data = myfile.read()\n","    obj = json.loads(data)\n","    prepare_idx(obj,video_input)\n","\n","\n","def  get_poseflow(video_input):\n","  if os.path.exists('image') :\n","    shutil.rmtree('image')\n","  os.mkdir(\"image\")\n","  !ffmpeg  -i $video_input -r 30 image/%d.jpg    #Extract images\n","\n","  if os.path.exists('Outimages') : shutil.rmtree('Outimages')\n","  os.mkdir (\"Outimages\")\n","  !pip install -q youtube-dl visdom\n","  os.chdir( \"AlphaPose\" )\n","  !python3 demo.py --sp --indir ../image/ --outdir ../.\n","  !pip2 install munkres==1.0.12   #poseflow\n","  os.chdir('/content/drive/My Drive/DetectConcealGun/app/files')\n","  !python2  AlphaPose/PoseFlow/tracker-general.py --imgdir image/ --in_json alphapose-results.json --out_json alphapose-results-forvis-tracked.json --visdir Outimages/\n","\n","  os.chdir('/content/drive/My Drive/DetectConcealGun')\n","  read_json(video_input)\n","\n","def get_length(filename):\n","  result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", filename], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n","  print('Video length : ' ,float(result.stdout))\n","  if float(result.stdout) < 2:\n","    print (\"Please upload your video less than 2 second\")\n","  elif float(result.stdout) > 100 :\n","    print (\"Sorry this video is more than 2 second video\")\n","  else :\n","    get_poseflow(filename)\n","\n","def main(videoName):\n","  os.chdir(\"/content/drive/My Drive/DetectConcealGun/app/files\")\n","  # videoName = str(input(\"Enter Video name : \"))\n","  get_length(videoName)\n","  # os.chdir(\"/content/drive/My Drive/DetectConcealGun\")\n","\n","\n","\n","def allowed_video(filename):\n","    if not \".\" in filename:\n","        return False\n","    ext = filename.rsplit(\".\", 1)[1]\n","    if ext.upper() in app.config[\"ALLOWED_VIDEO_EXTENSIONS\"]:\n","        return True\n","    else:\n","        return False\n","\n","@app.route(\"/\", methods=[\"GET\", \"POST\"])\n","def upload_video():\n","    if request.method == \"POST\":\n","        if request.files:\n","            video = request.files[\"video\"]\n","\n","            videoin = 'files/' + video.filename\n","\n","            if os.path.exists(videoin) :\n","              print('This is the same video')\n","              filename = secure_filename(video.filename)\n","              # read_json(filename)\n","              filenameout = 'results/result_' +secure_filename(video.filename)\n","              return render_template(\"public/result_video.html\", videoresult=filenameout)\n","\n","            if video.filename == \"\":\n","                # flash(\"No file\", \"warning\")\n","                return redirect(request.url)\n","\n","\n","            if allowed_video(video.filename):\n","                filename = secure_filename(video.filename)\n","                video.save(os.path.join(app.config[\"VIDEO_UPLOADS\"], filename))\n","                # flash(\"Video uploaded\", \"success\")\n","\n","\n","                # main(filename)\n","                read_json(filename)\n","                # framestoVDO(filename)\n","                \n","                # return redirect(request.url)\n","                filenameout = 'results/result_' + secure_filename(video.filename)\n","                return render_template(\"public/result_video.html\", videoresult=filenameout)\n","                # return redirect(url_for(\"result_detect\",filename=filename))\n","\n","            else:\n","                # flash(\"That file extension is not allowed\", \"danger\")\n","                return redirect(request.url)\n","    return render_template(\"public/upload_video.html\")\n","\n","\n","#PAGE\n","\n","@app.route(\"/about\")\n","def about():\n","    return render_template(\"public/about.html\")\n","  \n","@app.route(\"/result_video\")\n","def result_video():\n","  return render_template(\"public/result_video.html\")\n","\n","@app.route(\"/dataset\")\n","def video_dataset():\n","  return render_template(\"public/dataset.html\")\n","\n","\n","app.run()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8F17Cu78afyO","colab_type":"code","colab":{}},"source":["newjson = video_input.split(\".\")\n","dst_dir= '/content/drive/My Drive/DetectConcealGun/app/files/result'\n","src_file = '/content/drive/My Drive/DetectConcealGun/app/files/alphapose-results-forvis-tracked.json'\n","shutil.copy(src_file,dst_dir)\n","\n","dst_file = '/content/drive/My Drive/DetectConcealGun/app/files/result/alphapose-results-forvis-tracked.json'\n","new_dst_file_name = dst_dir + 'tracked_' + newjson[0] +'.json'\n","os.rename(dst_file, new_dst_file_name)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MU2CWiP__jED","colab_type":"text"},"source":["# Install flask"]},{"cell_type":"code","metadata":{"id":"XsapNAYt_nJz","colab_type":"code","outputId":"dbe9f92b-8e6c-479b-d491-238b44bb95d3","executionInfo":{"status":"ok","timestamp":1583288064860,"user_tz":-420,"elapsed":8147,"user":{"displayName":"PIMONPUN CHACHOMPHON","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjhjI8suu_5SmV03uqGiIwG7KaIUmD0V7yzyzaJ7jQ=s64","userId":"14117620575648423760"}},"colab":{"base_uri":"https://localhost:8080/","height":296}},"source":["!pip install flask-ngrok"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting flask-ngrok\n","  Downloading https://files.pythonhosted.org/packages/af/6c/f54cb686ad1129e27d125d182f90f52b32f284e6c8df58c1bae54fa1adbc/flask_ngrok-0.0.25-py3-none-any.whl\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.21.0)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n","Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.0)\n","Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.0)\n","Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n","Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"w0rXNJGM3s6u","colab_type":"text"},"source":["# New Section 2\n"]},{"cell_type":"code","metadata":{"id":"8Hu7ejD43uf1","colab_type":"code","outputId":"9dbdda71-9655-4950-84f9-f79c7bbefa1a","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from flask_ngrok import run_with_ngrok\n","from flask import Flask\n","from flask import render_template, request, redirect, flash, url_for\n","from werkzeug.utils import secure_filename\n","import os\n","import subprocess\n","import json\n","import pandas as pd\n","import numpy as np\n","import glob\n","import cv2\n","import pickle\n","from sklearn.preprocessing import StandardScaler\n","import shutil\n","import pathlib\n","from statistics import mean \n","\n","\n","app = Flask(__name__, static_folder=\"files\")\n","run_with_ngrok(app)   #starts ngrok when the app is run\n","\n","app.config[\"VIDEO_UPLOADS\"] = \"/content/drive/My Drive/DetectConcealGun/app/files\"\n","app.config[\"ALLOWED_VIDEO_EXTENSIONS\"] = [\"MP4\",\"MOV\",\"AVI\"]\n","\n","\n","def convert_tomp4(clipname):\n","  clipnames = clipname.split(\".\")\n","  avi_file_path = '/content/drive/My Drive/DetectConcealGun/app/files/result.avi'\n","  output_name = 'app/files/results/result_' + clipnames[0]\n","  print(output_name)\n","  os.popen(\"ffmpeg -i '{input}' -ac 2 -b:v 2000k -c:a aac -c:v libx264 -b:a 160k -vprofile high -bf 0 -strict experimental -f mp4 '{output}.mp4'\".format(input = avi_file_path, output = output_name))\n","  print(\"It's success!\")\n","\n","def framestoVDO(clipname):\n","  os.chdir(\"/content/drive/My Drive/DetectConcealGun\")\n","  path = 'app/files/images/'\n","  img_array = []\n","  for filename3 in glob.glob(path+'*.jpg'):\n","    img = cv2.imread(filename3)\n","    height, width, layers = img.shape\n","    sizes = (width,height)\n","    img_array.append(img) \n","  \n","  out = cv2.VideoWriter('app/files/result.avi', cv2.VideoWriter_fourcc(*'DIVX'), 30, sizes)\n","  for i in range(len(img_array)):\n","    out.write(img_array[i])\n","  out.release()\n","  print(\"video created\")\n","  convert_tomp4(clipname)\n","\n","\n","#NOTIFY LINE*****\n","\n","def notifyFile(filename2,video_input):\n","    file = {'imageFile':open(filename2,'rb')}\n","    payload = {'message': 'พบบุคคลที่มีความเสี่ยงในการอำพรางอาวุธปืนในพื้นที่ของคุณ!'}\n","    return _lineNotify(payload,file)\n","\n","def _lineNotify(payload,file=None):\n","    import requests\n","    url = 'https://notify-api.line.me/api/notify'\n","    token = '7JODPqwRqL73hrp1To1AYma0bI7evyKTcHtxXnjulWX'\t#EDIT\n","    headers = {'Authorization':'Bearer '+token}\n","    return requests.post(url, headers=headers , data = payload, files=file)\n","      \n","def Notify_Line(APIC,video_input):\n","  os.chdir(\"/content/drive/My Drive/DetectConcealGun/app/files\")\n","  aray1 = list()\n","  for f in glob.glob('images/*.jpg'):\n","      aa1 = (os.path.split(f)[-1])\n","      aray1.append(aa1)\n","  piclist = list()\n","  meanpic = list()\n","  for i in aray1 :\n","    person = APIC[APIC[0]==i]\n","    per = person[person['Class'] == 1]\n","    if len(per) > 0:\n","      bb = i\n","      piclist.append(bb)\n","    piclist_df = pd.DataFrame(piclist)\n","\n","  if len(piclist) != 0:\n","    for n in piclist : ##\n","      person = APIC[APIC[0]==n]\n","\n","      r =  [1.0,2.0,3.0,4.0,5.0]\n","      arealist = list()\n","      #Pose position person /\n","      for m in r :\n","        per = person[person[52] == m]\n","        if len(per) > 0:\n","          #select body point\n","          X_min = int(min(min(per[range(4,52,3)].values.tolist())))-50\n","          X_max = int(max(max(per[range(4,52,3)].values.tolist())))+100\n","          Y_min = int(min(min(per[range(2,52,3)].values.tolist())))-50\n","          Y_max = int(max(max(per[range(2,52,3)].values.tolist())))+100\n","          area = (Y_max-Y_min)*(X_max-X_min) #Box area \n","          arealist.append(int(area))\n","          meanlist = mean(arealist)\n","      meanpic.append(int(meanlist))\n","      meanpic_df = pd.DataFrame(meanpic)\n","    meanpic_df.reset_index(inplace=True) #set key\n","    piclist_df.reset_index(inplace=True)#set key\n","    meanpicdf = piclist_df.join(meanpic_df, on='index', how='left', rsuffix='mean')\n","    meanpicdf = meanpicdf.drop(columns=['index','indexmean'])\n","    Maxarea = meanpicdf.max()\n","  if len(piclist) != 0:\n","    nnoti = 'images/'+ Maxarea[0]\n","    notifyFile(nnoti,video_input)\n","\n","\n","def person_box(APIC,video_input):\n","  APIC3 = APIC\n","  aray = list()\n","  for f in glob.glob('app/files/image/*.jpg'):\n","      aa = (os.path.split(f)[-1])\n","      aray.append(aa)\n","\n","  if os.path.exists('app/files/images') :\n","    shutil.rmtree('app/files/images')\n","  os.mkdir('app/files/images')\n","  path = 'app/files/image/'\n","  for i in aray : ##\n","      images = cv2.imread(path+i,cv2.IMREAD_COLOR)\n","\n","      person = APIC[APIC[0]==i]\n","      r =  [1.0,2.0,3.0,4.0,5.0]\n","      #Pose position person /\n","      for m in r :\n","          per = person[person[52] == m]\n","          if len(per) > 0:\n","              #select body point\n","              X_min = int(min(min(per[range(4,52,3)].values.tolist())))-50\n","              X_max = int(max(max(per[range(4,52,3)].values.tolist())))+100\n","              Y_min = int(min(min(per[range(2,52,3)].values.tolist())))-50\n","              Y_max = int(max(max(per[range(2,52,3)].values.tolist())))+100\n","              clas = int(per['Class']) #\n","              if clas == 1:\n","                  color = (0,0,255) #RED\n","                  thickness = 20\n","                  images = cv2.rectangle(images, (X_max,Y_min), (X_min,Y_max), color, thickness)\n","                  scor = float(\"%.4f\"% per['Class_1'])*100\n","                  scor = float(\"%.4f\"% scor)\n","                  name = 'Gun'+': '+str(scor)+'%'\n","                  font = cv2.FONT_HERSHEY_SIMPLEX \n","                  fontScale = 2\n","                  # Line thickness of 2 px \n","                  thicknes = 7\n","                  images = cv2.putText(images, name, (X_max,Y_min-20), font, fontScale, color, thicknes, cv2.LINE_AA) \n","              else :\n","                  color = (0, 255, 0) #GREEN\n","                  thickness = 20\n","                  images = cv2.rectangle(images,(X_max,Y_min), (X_min,Y_max), color, thickness)\n","                  scor = float(\"%.4f\"% per['Class_0'])*100\n","                  scor = float(\"%.4f\"% scor)\n","                  name = 'None'+': '+str(scor)+'%'\n","                  font = cv2.FONT_HERSHEY_SIMPLEX\n","                  fontScale = 2\n","                  # Line thickness of 2 px \n","                  thicknes = 7\n","                  images = cv2.putText(images, name, (X_max,Y_min-20), font, fontScale, color, thicknes, cv2.LINE_AA)\n","              cv2.imwrite('app/files/images/'+i, images)\n","  Notify_Line(APIC3,video_input)\n","  framestoVDO(video_input) \n","\n","\n","def data_join (file1, file2,video_input):\n","  #load Class\n","  Class = pd.read_csv(file1) #2041(Class), 2042(Scores)\n","  #load APIC\n","  APIC = pd.read_csv(file2,header=None) \n","  r =  [1.0,2.0,3.0,4.0,5.0]\n","  m = range(0,5)\n","  A = APIC[52]\n","  B = APIC[52]#*Sores0\n","  C = APIC[52]#*Sores1\n","  for n in m :\n","    di = Class[Class['Unnamed: 0']==n]\n","    if len(di) > 0:\n","      clas = int(di['0_Predict'])\n","      cl = int(di['Unnamed: 0'])\n","      score_0 = float(di['Class_0'])\n","      score_1 = float(di['Class_1'])\n","      if cl == 0:\n","        A = A.replace(1.0,clas)\n","        B = B.replace(1.0,score_0)\n","        C = C.replace(1.0,score_1)\n","      elif cl == 1:\n","        A = A.replace(2.0,clas)\n","        B = B.replace(2.0,score_0)\n","        C = C.replace(2.0,score_1)\n","      elif cl == 2:\n","        A = A.replace(3.0,clas)\n","        B = B.replace(3.0,score_0)\n","        C = C.replace(3.0,score_1)\n","      elif cl == 3:\n","        A = A.replace(4.0,clas)\n","        B = B.replace(4.0,score_0)\n","        C = C.replace(4.0,score_1)\n","      elif cl == 4:\n","        A = A.replace(5.0,clas)\n","        B = B.replace(5.0,score_0)\n","        C = C.replace(5.0,score_1)\n","\n","  APIC['Class'] = A\n","  APIC['Class_0'] = B\n","  APIC['Class_1'] = C\n","  #check person\n","  person = len(Class)\n","  APICto = APIC[APIC[52] <= person]\n","  person_box(APICto,video_input)\n","\n","def mode_RF(Data,video_input): \n","  #reset index\n","  Data.reset_index(drop=True, inplace=True) \n","  X_test = Data.values.tolist()#dataframe to list\n","  \n","  #Load model\n","  filename = \"app/model_RF.pkl\"\n","  with open(filename, 'rb') as file:\n","    model = pickle.load(file)\n","  \n","  #prediction\n","  y_pred= model.predict(X_test)\n","\n","  # show the inputs and predicted outputs\n","  P_data=list()\n","  for i in range(len(X_test)):\n","    P_out = y_pred[i]\n","    P_data.append(P_out) \n","  # Calling DataFrame constructor on list \n","  P_datadf = pd.DataFrame(P_data) \n","  # check class\n","  Data.reset_index(drop=True, inplace=True)#reset index\n","  Data.reset_index(inplace=True) #set key\n","  P_datadf.reset_index(inplace=True)#set key\n","  # keep the predictions for class \n","  df = Data.join(P_datadf, on='index', how='left', rsuffix='_Predict') #join left\n","  df = df.drop(columns=['index_Predict']) #drop don't select\n","\n","    \n","  #prop each class\n","  prob = model.predict_proba(X_test)\n","  prob_out_df = list()\n","  for i in range(len(X_test)):\n","    prob_out = prob[i]\n","    prob_out_df.append(prob_out) \n","  # Calling DataFrame constructor on list \n","  prob_df = pd.DataFrame(prob_out_df) \n","  prob_df.reset_index(drop=True, inplace=True)#reset index\n","  prob_df.reset_index(inplace=True) #set key\n","  prob_df = prob_df.rename(columns={0: \"Class_0\", 1: \"Class_1\"}) #ChangName\n","  df = df.join(prob_df, on='index', how='left', rsuffix='_')\n","  df = df.drop(columns=['index_'])\n","\n","  # threshold < 0.6 \n","\n","  m = range(0,5)\n","  for n in m :\n","    di = df[df['index']==n]\n","    cla = di['Class_1'] \n","    for k in cla :\n","      if k < 0.6 :\n","        di['0_Predict'].replace({1: 0}, inplace=True)\n","    df[df['index']==n] = di\n","  df = df.drop(columns=['index'])\n","  print('Check Class for Prediction***', '\\n', df)\n","\n","  #Save .CSV\n","  df.to_csv('app/files/result_model_prediction.csv') #save result\n","  data_join ('app/files/result_model_prediction.csv', 'app/files/save_apic.csv',video_input)\n","\n","def data_train(video_input):\n","  file= 'app/files/Fature_to_Test.csv'\n","  Data = pd.read_csv(file,header=None)\n","  mode_RF(Data,video_input)\n","\n","def prepare_idx(idkp,video_input):\n","  maxjpg =[]\n","  for key, value in idkp.items():\n","    maxjpg.append(max([int(s) for s in key.split('.') if s.isdigit()]))\n","  maxjpg = max(maxjpg)\n","  print('max.jpg = ',maxjpg,'.jpg')\n","\n","  name_column=['XNose','YNose','XLEye','YLEye','XREye','YREye','XLEar','YLEar','XREar','YREar','XLShoulder','YLShoulder','XRShoulder','YRShoulder','XLElbow','YLElbow','XRElbow','YRElbow','XLWrist','YLWrist','XEWrist','YEWrist','XLHip','YLHip','XRHip','YRHip','XLKnee','YLKnee','XRKnee','YRKnee','XLAnkle','YLAnkle','XRAnkle','YRAnkle']\n","  featvec = list()\n","  for idxn in range(1,6,1) :\n","    # create list name pic .jpg ให้วนลูป\n","    jpglist  = list()\n","    pic = ['%s.jpg']\n","    for f in range(1,maxjpg+1,1): \n","      link = pic[0] % (f)\n","      jpglist.append(link)\n","\n","    frame, keypoints, idx = [], [] , []\n","    for key, value in idkp.items():\n","      picx = idkp[(key)]\n","      for p in picx:\n","        frame.append(key)\n","        keypoints.append(p['keypoints'])\n","        idx.append(p['idx'])\n","        df = pd.DataFrame() # create empty dataframe \n","        df['frame'] = frame\n","        df['keypoints'] = keypoints\n","        df['idx'] = idx\n","        apic = df\n","    \n","    jpglistdf = pd.DataFrame(jpglist, columns=['frame']) # Create jpglist dataframe\n","    pointn = apic[apic['idx'] == (idxn)]\n","    allFrame = pd.merge(jpglistdf , pointn[['frame', 'keypoints']], on='frame', how='left')\n","    # Replace NaN with list [-1,-1,-1, .  .  . ,-1] (51 item totol)\n","    allFrame.loc[allFrame['keypoints'].isnull(),['keypoints']] = allFrame.loc[allFrame['keypoints'].isnull(),'keypoints'].apply(lambda keypoints: [-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1,-1])\n","    # Keypoint\n","    kpall = allFrame['keypoints']\n","    # remove c \n","    keypointls = list()\n","    for frm in kpall:\n","      frm = [round(i,3) for i in frm]  # convert a list into list with 3 decimal places\n","      for i in frm:\n","        if i <= 1 and i >= 0 :\n","            frm.remove(i)\n","      keypointls.append(frm)\n","\n","    # convert list to array\n","    keypointar = np.asarray(keypointls)\n","\n","    #ปรับค่า X,Y Nose\n","    arrayper = keypointar\n","    X_Zero = arrayper[:,0] #X point Zero\n","    Y_Zero = arrayper[:,1] #Y point Zero\n","    l=list()\n","    for i in range(0, 34):\n","      if(i%2) == 0:\n","        A = abs(arrayper[:,i] - X_Zero)\n","      else:\n","        A = abs(arrayper[:,i] - Y_Zero)\n","      l.append(A)\n","\n","    #Z Score\n","    \n","    scaler = StandardScaler()\n","    scaler.fit(l)\n","    lstand = scaler.transform(l)\n","    datalistdf = pd.DataFrame(lstand, name_column)\n","    df = datalistdf.T\n","\n","    #กรณี มากกว่า 60 เฟรม จะเริ่มเก็บจากเฟรมสุดท้าย\n","    (naa,nbb) = lstand.shape\n","    D1 = list()\n","    for r in range(0,34):\n","      for t in range(nbb-60,nbb):\n","        dat1 = lstand[r,t]\n","        D1.append(dat1)\n","    datalistdf1 = pd.DataFrame(D1)\n","    df1 = datalistdf1.T\n","    df2 = df.values.tolist()\n","\n","    # กรณีที่จับได้น้อยกว่า 50%\n","    ccv0 = 0\n","    for cv1 in df2:\n","      for cv0 in cv1:\n","        if cv0 == 0:\n","          ccv0 = ccv0 + 1\n","    if ccv0 < 1500:  #old ccv0 < 1020\n","      featvec.append(df1)\n","\n","  featvec2 = pd.concat(featvec)\n","  np.savetxt('app/files/Fature_to_Test.csv', featvec2,delimiter=',' )\n","  np.savetxt('app/files/save_apic.csv',apic,fmt=['%s','%s', '%f'],delimiter=',')\n","  data_train(video_input)\n","\n","def read_json(video_input): #read json file\n","  os.chdir('/content/drive/My Drive/DetectConcealGun')\n","  with open('app/files/alphapose-results-forvis-tracked.json','r') as myfile:\n","    data = myfile.read()\n","    obj = json.loads(data)\n","    prepare_idx(obj,video_input)\n","\n","\n","def  get_poseflow(video_input):\n","  if os.path.exists('image') :\n","    shutil.rmtree('image')\n","  os.mkdir(\"image\")\n","  !ffmpeg  -i $video_input -r 30 image/%d.jpg    #Extract images\n","\n","  if os.path.exists('Outimages') : shutil.rmtree('Outimages')\n","  os.mkdir (\"Outimages\")\n","  !pip install -q youtube-dl visdom\n","  os.chdir( \"AlphaPose\" )\n","  !python3 demo.py --sp --indir ../image/ --outdir ../.\n","  !pip2 install munkres==1.0.12   #poseflow\n","  os.chdir('/content/drive/My Drive/DetectConcealGun/app/files')\n","  !python2  AlphaPose/PoseFlow/tracker-general.py --imgdir image/ --in_json alphapose-results.json --out_json alphapose-results-forvis-tracked.json --visdir Outimages/\n","  os.chdir('/content/drive/My Drive/DetectConcealGun')\n","  read_json(video_input)\n","\n","def get_length(filename):\n","  result = subprocess.run([\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\", \"-of\", \"default=noprint_wrappers=1:nokey=1\", filename], stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n","  print('Video length : ' ,float(result.stdout))\n","  if float(result.stdout) < 2:\n","    print (\"Please upload your video less than 2 second\")\n","  elif float(result.stdout) > 100 :\n","    print (\"Sorry this video is more than 2 second video\")\n","  else :\n","    get_poseflow(filename)\n","\n","def main(videoName):\n","  os.chdir(\"/content/drive/My Drive/DetectConcealGun/app/files\")\n","  # videoName = str(input(\"Enter Video name : \"))\n","  get_length(videoName)\n","  # os.chdir(\"/content/drive/My Drive/DetectConcealGun\")\n","\n","\n","\n","def allowed_video(filename):\n","    if not \".\" in filename:\n","        return False\n","    ext = filename.rsplit(\".\", 1)[1]\n","    if ext.upper() in app.config[\"ALLOWED_VIDEO_EXTENSIONS\"]:\n","        return True\n","    else:\n","        return False\n","\n","@app.route(\"/\", methods=[\"GET\", \"POST\"])\n","def upload_video():\n","    if request.method == \"POST\":\n","        if request.files:\n","            video = request.files[\"video\"]\n","\n","            videoin = 'files/' + video.filename\n","\n","            if os.path.exists(videoin) :\n","              print('This is the same video')\n","              filename = secure_filename(video.filename)\n","              # read_json(filename)\n","              filenameout = 'results/result_' +secure_filename(video.filename)\n","              return render_template(\"public/result_video.html\", videoresult=filenameout)\n","\n","            if video.filename == \"\":\n","                # flash(\"No file\", \"warning\")\n","                return redirect(request.url)\n","\n","\n","            if allowed_video(video.filename):\n","                filename = secure_filename(video.filename)\n","                video.save(os.path.join(app.config[\"VIDEO_UPLOADS\"], filename))\n","                # flash(\"Video uploaded\", \"success\")\n","\n","\n","                main(filename)\n","                # read_json(filename)\n","                # framestoVDO(filename)\n","                \n","                # return redirect(request.url)\n","                filenameout = 'results/result_' + secure_filename(video.filename)\n","                return render_template(\"public/result_video.html\", videoresult=filenameout)\n","                # return redirect(url_for(\"result_detect\",filename=filename))\n","\n","            else:\n","                # flash(\"That file extension is not allowed\", \"danger\")\n","                return redirect(request.url)\n","    return render_template(\"public/upload_video.html\")\n","\n","\n","#PAGE\n","\n","@app.route(\"/about\")\n","def about():\n","    return render_template(\"public/about.html\")\n","  \n","@app.route(\"/result_video\")\n","def result_video():\n","  return render_template(\"public/result_video.html\")\n","\n","@app.route(\"/dataset\")\n","def video_dataset():\n","  return render_template(\"public/dataset.html\")\n","\n","\n","app.run()"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","   WARNING: This is a development server. Do not use it in a production deployment.\n","   Use a production WSGI server instead.\n"," * Debug mode: off\n"],"name":"stdout"},{"output_type":"stream","text":[" * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"],"name":"stderr"},{"output_type":"stream","text":[" * Running on http://253e62d6.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [04/Mar/2020 02:14:36] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 02:14:37] \"\u001b[37mGET /files/css/style.css HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 02:14:38] \"\u001b[37mGET /files/js/app.js HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 02:14:39] \"\u001b[37mGET /files/css/gun32.png HTTP/1.1\u001b[0m\" 200 -\n"],"name":"stderr"},{"output_type":"stream","text":["Video length :  2.047958\n","ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'QqBamNKW4KU_dup1_Test402.mp4':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp41isom\n","    creation_time   : 2019-12-18T07:13:50.000000Z\n","  Duration: 00:00:02.05, start: 0.000000, bitrate: 837 kb/s\n","    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 718 kb/s, 30 fps, 30 tbr, 30k tbn, 60 tbc (default)\n","    Metadata:\n","      creation_time   : 2020-02-19T06:41:18.000000Z\n","      handler_name    : VideoHandler\n","      encoder         : AVC Coding\n","    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 117 kb/s (default)\n","    Metadata:\n","      creation_time   : 2020-02-19T06:41:18.000000Z\n","      handler_name    : SoundHandler\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n","Press [q] to stop, [?] for help\n","\u001b[1;34m[swscaler @ 0x5576e0c82000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n","\u001b[0mOutput #0, image2, to 'image/%d.jpg':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp41isom\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n","    Metadata:\n","      creation_time   : 2020-02-19T06:41:18.000000Z\n","      handler_name    : VideoHandler\n","      encoder         : Lavc57.107.100 mjpeg\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n","frame=   61 fps= 40 q=24.8 Lsize=N/A time=00:00:02.03 bitrate=N/A speed=1.34x    \n","video:3048kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n","\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n","\u001b[K     |████████████████████████████████| 686kB 52.3MB/s \n","\u001b[K     |████████████████████████████████| 204kB 40.3MB/s \n","\u001b[?25h  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Loading YOLO model..\n","Loading pose model from ./models/sppe/duc_se.pth\n","100% 61/61 [00:09<00:00,  5.22it/s]\n","===========================> Finish Model Running.\n","Collecting munkres==1.0.12\n","  Downloading https://files.pythonhosted.org/packages/ea/f3/21d3c23017ba987e77286c5f7b6334366777919ced67f6bb9d48f5f5936c/munkres-1.0.12-py2.py3-none-any.whl\n","Installing collected packages: munkres\n","Successfully installed munkres-1.0.12\n","Start loading json file...\n","\n","100% 61/61 [00:03<00:00, 19.56it/s]\n","Start pose tracking...\n","\n","100% 60/60 [02:53<00:00,  2.68s/it]\n","This video contains 4 people.\n","Export tracking results to json...\n","\n","100% 61/61 [00:00<00:00, 56380.02it/s]\n","Start visualization...\n","\n"," 39% 24/61 [00:20<00:32,  1.15it/s]"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [04/Mar/2020 02:21:55] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"],"name":"stderr"},{"output_type":"stream","text":["100% 61/61 [00:53<00:00,  1.14it/s]\n","max.jpg =  61 .jpg\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6786: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._update_inplace(new_data)\n"],"name":"stderr"},{"output_type":"stream","text":["Check Class for Prediction*** \n","           0         1         2  ...  0_Predict   Class_0   Class_1\n","0 -0.989715 -0.980586 -0.987551  ...          0  0.821667  0.178333\n","1 -0.904263 -0.899140 -0.908894  ...          1  0.083333  0.916667\n","2 -1.120850 -1.068504 -1.043034  ...          0  0.620000  0.380000\n","\n","[3 rows x 2043 columns]\n","video created\n","app/files/results/result_QqBamNKW4KU_dup1_Test402\n","It's success!\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [04/Mar/2020 02:22:58] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"],"name":"stderr"},{"output_type":"stream","text":["Video length :  2.047958\n","ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n","  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n","  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n","  libavutil      55. 78.100 / 55. 78.100\n","  libavcodec     57.107.100 / 57.107.100\n","  libavformat    57. 83.100 / 57. 83.100\n","  libavdevice    57. 10.100 / 57. 10.100\n","  libavfilter     6.107.100 /  6.107.100\n","  libavresample   3.  7.  0 /  3.  7.  0\n","  libswscale      4.  8.100 /  4.  8.100\n","  libswresample   2.  9.100 /  2.  9.100\n","  libpostproc    54.  7.100 / 54.  7.100\n","Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'QqBamNKW4KU_dup1_Test402.mp4':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp41isom\n","    creation_time   : 2019-12-18T07:13:50.000000Z\n","  Duration: 00:00:02.05, start: 0.000000, bitrate: 837 kb/s\n","    Stream #0:0(und): Video: h264 (Main) (avc1 / 0x31637661), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], 718 kb/s, 30 fps, 30 tbr, 30k tbn, 60 tbc (default)\n","    Metadata:\n","      creation_time   : 2020-02-19T06:41:18.000000Z\n","      handler_name    : VideoHandler\n","      encoder         : AVC Coding\n","    Stream #0:1(und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, stereo, fltp, 117 kb/s (default)\n","    Metadata:\n","      creation_time   : 2020-02-19T06:41:18.000000Z\n","      handler_name    : SoundHandler\n","Stream mapping:\n","  Stream #0:0 -> #0:0 (h264 (native) -> mjpeg (native))\n","Press [q] to stop, [?] for help\n","\u001b[1;34m[swscaler @ 0x55b835db6000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n","\u001b[0mOutput #0, image2, to 'image/%d.jpg':\n","  Metadata:\n","    major_brand     : mp42\n","    minor_version   : 0\n","    compatible_brands: mp41isom\n","    encoder         : Lavf57.83.100\n","    Stream #0:0(und): Video: mjpeg, yuvj420p(pc), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 30 fps, 30 tbn, 30 tbc (default)\n","    Metadata:\n","      creation_time   : 2020-02-19T06:41:18.000000Z\n","      handler_name    : VideoHandler\n","      encoder         : Lavc57.107.100 mjpeg\n","    Side data:\n","      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: -1\n","frame=   61 fps= 39 q=24.8 Lsize=N/A time=00:00:02.03 bitrate=N/A speed=1.31x    \n","video:3048kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n","Loading YOLO model..\n","Loading pose model from ./models/sppe/duc_se.pth\n","100% 61/61 [00:10<00:00,  5.33it/s]\n","===========================> Finish Model Running.\n","Requirement already satisfied: munkres==1.0.12 in /usr/local/lib/python2.7/dist-packages (1.0.12)\n","Start loading json file...\n","\n","100% 61/61 [00:02<00:00, 20.54it/s]\n","Start pose tracking...\n","\n","100% 60/60 [02:51<00:00,  2.66s/it]\n","This video contains 4 people.\n","Export tracking results to json...\n","\n","100% 61/61 [00:00<00:00, 60158.13it/s]\n","Start visualization...\n","\n","100% 61/61 [00:53<00:00,  1.12it/s]\n","max.jpg =  61 .jpg\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py:6786: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._update_inplace(new_data)\n"],"name":"stderr"},{"output_type":"stream","text":["Check Class for Prediction*** \n","           0         1         2  ...  0_Predict   Class_0   Class_1\n","0 -0.989715 -0.980586 -0.987551  ...          0  0.821667  0.178333\n","1 -0.904263 -0.899140 -0.908894  ...          1  0.083333  0.916667\n","2 -1.120850 -1.068504 -1.043034  ...          0  0.620000  0.380000\n","\n","[3 rows x 2043 columns]\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [04/Mar/2020 02:28:26] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 200 -\n"],"name":"stderr"},{"output_type":"stream","text":["video created\n","app/files/results/result_QqBamNKW4KU_dup1_Test402\n","It's success!\n"],"name":"stdout"},{"output_type":"stream","text":["127.0.0.1 - - [04/Mar/2020 02:28:28] \"\u001b[37mGET /files/css/gun32.png HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 02:28:32] \"\u001b[37mGET /files/results/result_QqBamNKW4KU_dup1_Test402.mp4 HTTP/1.1\u001b[0m\" 206 -\n","127.0.0.1 - - [04/Mar/2020 02:28:33] \"\u001b[37mGET /files/results/result_QqBamNKW4KU_dup1_Test402.mp4 HTTP/1.1\u001b[0m\" 206 -\n","127.0.0.1 - - [04/Mar/2020 02:28:34] \"\u001b[37mGET /files/results/result_QqBamNKW4KU_dup1_Test402.mp4 HTTP/1.1\u001b[0m\" 206 -\n","127.0.0.1 - - [04/Mar/2020 02:44:48] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 02:47:40] \"\u001b[37mGET /about HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 02:47:48] \"\u001b[37mGET /dataset HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 02:47:49] \"\u001b[37mGET /files/css/picdataset.jpg HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 03:16:30] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 06:31:12] \"\u001b[37mGET /about HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 06:31:14] \"\u001b[37mGET /dataset HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 06:31:16] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 06:32:22] \"\u001b[37mGET /about HTTP/1.1\u001b[0m\" 200 -\n","127.0.0.1 - - [04/Mar/2020 07:39:58] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"],"name":"stderr"}]}]}